{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15961f18-d3a9-487a-bdcb-8262a3559aba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Long Form Text Summarization using JumpStart Foundation Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6878b09a-a77a-4e45-bed9-c5d86c92b6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install cohere_sagemaker\n",
    "!pip install pandas\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a91625-57ea-4b19-be66-58a0155492d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part - I: Hosting the foundation model for real-time inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd748ea5-ae04-4d85-8a6e-fe6632b7ecd5",
   "metadata": {},
   "source": [
    "#### I. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14875767-3da4-4c00-8ea9-fa62a3c3ed71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from cohere_sagemaker import CohereError\n",
    "from cohere_sagemaker import Client\n",
    "from sagemaker import ModelPackage\n",
    "import cohere_sagemaker\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d35c85-fac3-4fa6-877a-2246fba8f721",
   "metadata": {},
   "source": [
    "#### Setup Logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e14df3-fca6-4bdb-8a08-38d7317e2510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a268eb12-e655-447b-97dd-7a58259823d2",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da9b21-2e08-418f-8c4b-42b2a33ddf61",
   "metadata": {},
   "source": [
    "#### II. Setup essentials "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc66e6-5320-4cf0-97bc-3431c1fe3119",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mapping for Model Packages (initially only us-east-1 and eu-west-1 is supported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0003673-c89d-451d-9e64-a7cbdb12ff79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_map = {\n",
    "    'us-east-1': 'arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421',\n",
    "    'eu-west-1': 'arn:aws:sagemaker:eu-west-1:985815980388:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc6314-af70-4c0e-948b-07281f92fadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "logger.info(f'Region = {region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2390933-932e-40fa-9a43-184732af08bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if region not in model_package_map.keys():\n",
    "    raise Exception(f'Unsupported region = {region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda2dc1-8d66-469d-a55a-88800189aa5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PACKAGE_ARN = model_package_map[region]\n",
    "logger.info(f'Model package ARN = {MODEL_PACKAGE_ARN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad4e24-3a4f-48c7-b101-d5beebc671f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROLE = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "logger.info(f'Role = {ROLE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058120d-959c-438d-84dd-654a4a59b281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = int(time.time())\n",
    "MODEL_NAME = f'cohere-medium-{timestamp}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df073add-7a6c-4cc2-9f18-f1ac530656c6",
   "metadata": {},
   "source": [
    "#### III. Create a SageMaker endpoint for real-time inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc86f6-80cd-4a69-9cc8-d1a6d8eec9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ModelPackage(role=ROLE, \n",
    "                     model_package_arn=MODEL_PACKAGE_ARN, \n",
    "                     sagemaker_session=session, \n",
    "                     name=MODEL_NAME)\n",
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66dc5c-566b-4676-bdbb-88859b5588a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_INSTANCES = 1\n",
    "INSTANCE_TYPE = 'ml.g5.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235c65cd-2b70-4f3d-8ab9-05d24f47a4a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.deploy(NUM_INSTANCES, \n",
    "             INSTANCE_TYPE, \n",
    "             endpoint_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a49ff-04e0-4955-bf38-bf5188c5445d",
   "metadata": {},
   "source": [
    "## Part 2: Long-form abstractive text summarization of legal judgement docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea909b2-32d1-496c-b9f2-ff64687d21d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### I. Read, parse and chunk docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0292a2c-f748-4a70-bbb5-99abb1c3d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_name = '5.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "398c16c4-227e-453d-b1de-a797e9df3745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_lines = []\n",
    "with open(f'./docs/{doc_name}', encoding='iso-8859-1') as doc:\n",
    "    for line in doc.readlines():\n",
    "        line = line.strip()\n",
    "        line = re.sub(' +', ' ', line)\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.replace('\\t', '')\n",
    "        line = line.replace('  ', ' ')\n",
    "        if len(line) > 0:\n",
    "            cleaned_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04bf171-b616-40ef-88a5-3af6684ca010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = ' '.join(cleaned_lines)\n",
    "doc = doc.split()\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97c3297f-b741-41c8-b051-2932dc480306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 768\n",
    "chunks = [' '.join(doc[i:i+chunk_size]) for i in range(0, len(doc), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd4c8b-71cc-46ef-a666-361ccb1f49b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e178c9-371f-4320-8675-94676147af97",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### II. Short-form Abstractive Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad86bc79-1df9-45af-aa66-4073b8269f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = 'cohere-medium-1679931302'\n",
    "# ENDPOINT_NAME = MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c683d6bb-196d-4779-bd3e-c5cc92556988",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(endpoint_name=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "398cefc4-9fe3-4b4e-ad7d-acbe5dcafc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_by_chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9272c2c-9b82-4958-982b-fc692ac5b2a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "for chunk in tqdm(chunks):\n",
    "    prompt = f'Context = {chunk}\\nSummarize the above context.'\n",
    "    response = client.generate(prompt=prompt, \n",
    "                           max_tokens=256, \n",
    "                           temperature=0.2, \n",
    "                           return_likelihoods='GENERATION')\n",
    "    generated_text = response.generations[0].text\n",
    "    summaries_by_chunks.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "84046d3c-3621-4cee-836b-dc0d29ae5e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_summaries = []\n",
    "STOP_SEQ = '. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e934d7bb-56a9-46cf-8e79-546dbe4c5ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_summary(summary):\n",
    "    valid_sents = []\n",
    "    sents = summary.split(STOP_SEQ)\n",
    "    last_sent = sents[-1]\n",
    "    if not last_sent.endswith('.'):\n",
    "        sents = sents[0:-2]\n",
    "    return ' '.join(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a6403ef8-e20c-450e-8833-efc26c76b4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for summary in summaries_by_chunks:\n",
    "    summary = summary.replace('\\n', '')\n",
    "    summary = summary.replace('  ', ' ')\n",
    "    summary = summary.replace('\\'', '')\n",
    "    summary = summary.strip()\n",
    "    cleaned_summary = clean_summary(summary)\n",
    "    if not cleaned_summary.endswith('.'):\n",
    "        cleaned_summary = cleaned_summary + '.'\n",
    "    if len(cleaned_summary) >= 64:  # atleast 64 chars\n",
    "        cleaned_summaries.append(cleaned_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2937605-d14b-47d8-897b-6e00e5def613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(f'Total number of short summaries generated = {len(cleaned_summaries)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced2a16-6104-48ec-b224-6bb772f03329",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### III. Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0166b9f9-f74e-41d2-843e-9ad947e0f0de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions_map = {}\n",
    "total_questions_generated = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "24f4ddd9-1ae3-4f44-b338-e1a48affd4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detect_words = ['why', 'how', 'what', 'who', 'where', 'is', 'when', 'which', 'whose', 'are', 'do', 'does', 'can', 'could', 'should', 'will', 'have', 'has']\n",
    "\n",
    "def is_a_question(question):\n",
    "    first_word = question.split()[0]\n",
    "    if first_word.lower() in detect_words:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ddcaf-9855-424c-9ce1-ad0e808329d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for summary in tqdm(cleaned_summaries):\n",
    "        prompt = f\"\"\"EXTRACT QUESTIONS\n",
    "        Context: \n",
    "        {summary}\n",
    "        Questions:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = client.generate(prompt=prompt, \n",
    "                                   max_tokens=512, \n",
    "                                   temperature=0, \n",
    "                                   return_likelihoods='GENERATION')\n",
    "            generated_text = response.generations[0].text\n",
    "            questions = generated_text.split('\\n')\n",
    "            cleaned_questions = set()\n",
    "            for question in questions:\n",
    "                if len(question) > 5:\n",
    "                    question = re.sub(r'\\d+\\.', '', question)\n",
    "                    question = question.replace('Q:', '')\n",
    "                    question = question.strip()\n",
    "                    if is_a_question(question) is True:\n",
    "                        cleaned_questions.add(question)\n",
    "            total_questions_generated += len(cleaned_questions)\n",
    "            questions_map[summary] = cleaned_questions\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ccdb9-4004-4865-b095-71840b7ce90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(f'Total questions generated = {total_questions_generated}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a726a133-93b9-4a77-a296-d77f3da4dea0",
   "metadata": {},
   "source": [
    "#### 4. Abstractive Question & Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e49f01-d549-4d1c-a527-56a1ced04b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "qa_pairs = []\n",
    "\n",
    "for context, questions in tqdm(questions_map.items()):\n",
    "    for question in questions:\n",
    "        prompt = f\"\"\"Context = {context}\n",
    "        Question = {question}\n",
    "        Answer = \n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = client.generate(prompt=prompt, \n",
    "                               max_tokens=128, \n",
    "                               temperature=0, \n",
    "                               return_likelihoods='GENERATION')\n",
    "\n",
    "            generated_text = response.generations[0].text\n",
    "            answer = generated_text.strip()\n",
    "            qa_pairs.append((doc_name, context, question, answer))\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2ed3e-b255-4ff3-9141-bcae17413612",
   "metadata": {},
   "source": [
    "#### 5. Combine short summaries into a long form summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "951e0770-dcf6-445a-b1db-ccf6b3c16692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_form_summary = []\n",
    "for short_summary in cleaned_summaries:\n",
    "    short_summary = short_summary.replace('\\'', '')\n",
    "    long_form_summary.append(short_summary)\n",
    "long_form_summary = '\\n\\n'.join(long_form_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8681ce1-957b-4d06-a19e-f17655d689d5",
   "metadata": {},
   "source": [
    "#### 6. Write long form summary and QA pairs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3175b0f3-b6c3-43a6-b918-c53052eb452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./summaries/summary_5.txt', 'w') as out:\n",
    "    out.write(long_form_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f649fe-4eff-4fc9-af77-5a144b9d2fb6",
   "metadata": {},
   "source": [
    "#### 7. Write QA pairs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb9d45-9649-4c91-896c-22c416a21615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(qa_pairs, columns=['doc_name', 'short_summary', 'question', 'answer'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "085a52a8-ef54-43aa-af1b-f0a3385c8a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('./qa_pairs/qa_pairs_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f965d-7f58-45ed-80e7-cd93b82e9d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
