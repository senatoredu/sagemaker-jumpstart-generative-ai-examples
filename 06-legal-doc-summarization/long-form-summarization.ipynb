{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15961f18-d3a9-487a-bdcb-8262a3559aba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Long Form Text Summarization using JumpStart Foundation Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6878b09a-a77a-4e45-bed9-c5d86c92b6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install cohere_sagemaker\n",
    "!pip install pandas\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a91625-57ea-4b19-be66-58a0155492d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part - I: Hosting the foundation model for real-time inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd748ea5-ae04-4d85-8a6e-fe6632b7ecd5",
   "metadata": {},
   "source": [
    "#### I. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14875767-3da4-4c00-8ea9-fa62a3c3ed71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from cohere_sagemaker import CohereError\n",
    "from cohere_sagemaker import Client\n",
    "from sagemaker import ModelPackage\n",
    "import cohere_sagemaker\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d35c85-fac3-4fa6-877a-2246fba8f721",
   "metadata": {},
   "source": [
    "#### Setup Logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e14df3-fca6-4bdb-8a08-38d7317e2510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a268eb12-e655-447b-97dd-7a58259823d2",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e312761d-7a08-4038-94a8-03034092031d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using SageMaker version: 2.146.0]\n",
      "[Using SageMaker version: 2.146.0]\n",
      "[Using Boto3 version: 1.26.114]\n",
      "[Using Boto3 version: 1.26.114]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using SageMaker version: {sagemaker.__version__}]')\n",
    "logger.info(f'[Using Boto3 version: {boto3.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da9b21-2e08-418f-8c4b-42b2a33ddf61",
   "metadata": {},
   "source": [
    "#### II. Setup essentials "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc66e6-5320-4cf0-97bc-3431c1fe3119",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mapping for Model Packages (initially only us-east-1 and eu-west-1 is supported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0003673-c89d-451d-9e64-a7cbdb12ff79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_map = {\n",
    "    'us-east-1': 'arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421',\n",
    "    'eu-west-1': 'arn:aws:sagemaker:eu-west-1:985815980388:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbbc6314-af70-4c0e-948b-07281f92fadd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Region = us-east-1\n",
      "Region = us-east-1\n"
     ]
    }
   ],
   "source": [
    "region = boto3.Session().region_name\n",
    "logger.info(f'Region = {region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2390933-932e-40fa-9a43-184732af08bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if region not in model_package_map.keys():\n",
    "    raise Exception(f'Unsupported region = {region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dda2dc1-8d66-469d-a55a-88800189aa5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model package ARN = arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421\n",
      "Model package ARN = arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421\n"
     ]
    }
   ],
   "source": [
    "MODEL_PACKAGE_ARN = model_package_map[region]\n",
    "logger.info(f'Model package ARN = {MODEL_PACKAGE_ARN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abad4e24-3a4f-48c7-b101-d5beebc671f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Role = arn:aws:iam::781085584109:role/service-role/AmazonSageMaker-ExecutionRole-20230516T110280\n",
      "Role = arn:aws:iam::781085584109:role/service-role/AmazonSageMaker-ExecutionRole-20230516T110280\n"
     ]
    }
   ],
   "source": [
    "ROLE = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "logger.info(f'Role = {ROLE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a058120d-959c-438d-84dd-654a4a59b281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = int(time.time())\n",
    "MODEL_NAME = f'cohere-medium-{timestamp}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df073add-7a6c-4cc2-9f18-f1ac530656c6",
   "metadata": {},
   "source": [
    "#### III. Create a SageMaker endpoint for real-time inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7bc86f6-80cd-4a69-9cc8-d1a6d8eec9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_data': None,\n",
       " 'image_uri': None,\n",
       " 'predictor_cls': None,\n",
       " 'env': {},\n",
       " 'name': 'cohere-medium-1684199676',\n",
       " '_base_name': None,\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7fbd323a0c40>,\n",
       " 'role': 'arn:aws:iam::781085584109:role/service-role/AmazonSageMaker-ExecutionRole-20230516T110280',\n",
       " 'vpc_config': None,\n",
       " 'endpoint_name': None,\n",
       " '_is_compiled_model': False,\n",
       " '_compilation_job_name': None,\n",
       " '_is_edge_packaged_model': False,\n",
       " 'inference_recommender_job_results': None,\n",
       " 'inference_recommendations': None,\n",
       " '_enable_network_isolation': False,\n",
       " 'model_kms_key': None,\n",
       " 'image_config': None,\n",
       " 'entry_point': None,\n",
       " 'source_dir': None,\n",
       " 'dependencies': [],\n",
       " 'git_config': None,\n",
       " 'container_log_level': 20,\n",
       " 'bucket': None,\n",
       " 'key_prefix': None,\n",
       " 'uploaded_code': None,\n",
       " 'repacked_model_data': None,\n",
       " 'algorithm_arn': None,\n",
       " 'model_package_arn': 'arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421',\n",
       " '_created_model_package_name': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelPackage(role=ROLE, \n",
    "                     model_package_arn=MODEL_PACKAGE_ARN, \n",
    "                     sagemaker_session=session, \n",
    "                     name=MODEL_NAME)\n",
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad66dc5c-566b-4676-bdbb-88859b5588a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_INSTANCES = 1\n",
    "INSTANCE_TYPE = 'ml.g5.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "235c65cd-2b70-4f3d-8ab9-05d24f47a4a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating model with name: cohere-medium-1684199676\n",
      "Creating model with name: cohere-medium-1684199676\n",
      "CreateModel request: {\n",
      "    \"ModelName\": \"cohere-medium-1684199676\",\n",
      "    \"ExecutionRoleArn\": \"arn:aws:iam::781085584109:role/service-role/AmazonSageMaker-ExecutionRole-20230516T110280\",\n",
      "    \"Containers\": [\n",
      "        {\n",
      "            \"ModelPackageName\": \"arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421\"\n",
      "        }\n",
      "    ],\n",
      "    \"EnableNetworkIsolation\": true\n",
      "}\n",
      "CreateModel request: {\n",
      "    \"ModelName\": \"cohere-medium-1684199676\",\n",
      "    \"ExecutionRoleArn\": \"arn:aws:iam::781085584109:role/service-role/AmazonSageMaker-ExecutionRole-20230516T110280\",\n",
      "    \"Containers\": [\n",
      "        {\n",
      "            \"ModelPackageName\": \"arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421\"\n",
      "        }\n",
      "    ],\n",
      "    \"EnableNetworkIsolation\": true\n",
      "}\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateModel operation: Caller is not subscribed to the marketplace offering.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/model.py:1248\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_name, compiled_model_suffix))\n\u001b[0;32m-> 1248\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_sagemaker_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m serverless_inference_config_dict \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1253\u001b[0m     serverless_inference_config\u001b[38;5;241m.\u001b[39m_to_request_dict() \u001b[38;5;28;01mif\u001b[39;00m is_serverless \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1254\u001b[0m )\n\u001b[1;32m   1255\u001b[0m production_variant \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mproduction_variant(\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1257\u001b[0m     instance_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     container_startup_health_check_timeout\u001b[38;5;241m=\u001b[39mcontainer_startup_health_check_timeout,\n\u001b[1;32m   1264\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/model.py:1725\u001b[0m, in \u001b[0;36mModelPackage._create_sagemaker_model\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_base_name_if_needed(model_package_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_model_name_if_needed()\n\u001b[0;32m-> 1725\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrole\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontainer_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvpc_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvpc_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_network_isolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_network_isolation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:3391\u001b[0m, in \u001b[0;36mSession.create_model\u001b[0;34m(self, name, role, container_defs, vpc_config, enable_network_isolation, primary_container, tags)\u001b[0m\n\u001b[1;32m   3388\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3389\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 3391\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_model_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m name\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:5375\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   5358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   5359\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5360\u001b[0m     request: typing\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5363\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   5364\u001b[0m ):\n\u001b[1;32m   5365\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   5366\u001b[0m \n\u001b[1;32m   5367\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5373\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   5374\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:3379\u001b[0m, in \u001b[0;36mSession.create_model.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   3377\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreateModel request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m   3378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3379\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3381\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:960\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateModel operation: Caller is not subscribed to the marketplace offering."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.deploy(NUM_INSTANCES, \n",
    "             INSTANCE_TYPE, \n",
    "             endpoint_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a49ff-04e0-4955-bf38-bf5188c5445d",
   "metadata": {},
   "source": [
    "## Part 2: Long-form abstractive text summarization of legal judgement docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea909b2-32d1-496c-b9f2-ff64687d21d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### I. Read, parse and chunk docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0292a2c-f748-4a70-bbb5-99abb1c3d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_name = '5.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "398c16c4-227e-453d-b1de-a797e9df3745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_lines = []\n",
    "with open(f'./docs/{doc_name}', encoding='iso-8859-1') as doc:\n",
    "    for line in doc.readlines():\n",
    "        line = line.strip()\n",
    "        line = re.sub(' +', ' ', line)\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.replace('\\t', '')\n",
    "        line = line.replace('  ', ' ')\n",
    "        if len(line) > 0:\n",
    "            cleaned_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e04bf171-b616-40ef-88a5-3af6684ca010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4168"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = ' '.join(cleaned_lines)\n",
    "doc = doc.split()\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97c3297f-b741-41c8-b051-2932dc480306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 768\n",
    "chunks = [' '.join(doc[i:i+chunk_size]) for i in range(0, len(doc), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1bd4c8b-71cc-46ef-a666-361ccb1f49b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e178c9-371f-4320-8675-94676147af97",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### II. Short-form Abstractive Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad86bc79-1df9-45af-aa66-4073b8269f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = 'cohere-medium-1679931302'\n",
    "# ENDPOINT_NAME = MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c683d6bb-196d-4779-bd3e-c5cc92556988",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(endpoint_name=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "398cefc4-9fe3-4b4e-ad7d-acbe5dcafc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_by_chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f9272c2c-9b82-4958-982b-fc692ac5b2a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:43<00:00,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 ms, sys: 11.5 ms, total: 50.5 ms\n",
      "Wall time: 43.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "for chunk in tqdm(chunks):\n",
    "    prompt = f'Context = {chunk}\\nSummarize the above context.'\n",
    "    response = client.generate(prompt=prompt, \n",
    "                           max_tokens=256, \n",
    "                           temperature=0.2, \n",
    "                           return_likelihoods='GENERATION')\n",
    "    generated_text = response.generations[0].text\n",
    "    summaries_by_chunks.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "84046d3c-3621-4cee-836b-dc0d29ae5e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_summaries = []\n",
    "STOP_SEQ = '. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e934d7bb-56a9-46cf-8e79-546dbe4c5ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_summary(summary):\n",
    "    valid_sents = []\n",
    "    sents = summary.split(STOP_SEQ)\n",
    "    last_sent = sents[-1]\n",
    "    if not last_sent.endswith('.'):\n",
    "        sents = sents[0:-2]\n",
    "    return ' '.join(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a6403ef8-e20c-450e-8833-efc26c76b4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for summary in summaries_by_chunks:\n",
    "    summary = summary.replace('\\n', '')\n",
    "    summary = summary.replace('  ', ' ')\n",
    "    summary = summary.replace('\\'', '')\n",
    "    summary = summary.strip()\n",
    "    cleaned_summary = clean_summary(summary)\n",
    "    if not cleaned_summary.endswith('.'):\n",
    "        cleaned_summary = cleaned_summary + '.'\n",
    "    if len(cleaned_summary) >= 64:  # atleast 64 chars\n",
    "        cleaned_summaries.append(cleaned_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d2937605-d14b-47d8-897b-6e00e5def613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total number of short summaries generated = 6\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Total number of short summaries generated = {len(cleaned_summaries)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced2a16-6104-48ec-b224-6bb772f03329",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### III. Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0166b9f9-f74e-41d2-843e-9ad947e0f0de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions_map = {}\n",
    "total_questions_generated = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "24f4ddd9-1ae3-4f44-b338-e1a48affd4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detect_words = ['why', 'how', 'what', 'who', 'where', 'is', 'when', 'which', 'whose', 'are', 'do', 'does', 'can', 'could', 'should', 'will', 'have', 'has']\n",
    "\n",
    "def is_a_question(question):\n",
    "    first_word = question.split()[0]\n",
    "    if first_word.lower() in detect_words:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cb4ddcaf-9855-424c-9ce1-ad0e808329d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:22<00:00, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.6 ms, sys: 5.12 ms, total: 38.8 ms\n",
      "Wall time: 1min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for summary in tqdm(cleaned_summaries):\n",
    "        prompt = f\"\"\"EXTRACT QUESTIONS\n",
    "        Context: \n",
    "        {summary}\n",
    "        Questions:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = client.generate(prompt=prompt, \n",
    "                                   max_tokens=512, \n",
    "                                   temperature=0, \n",
    "                                   return_likelihoods='GENERATION')\n",
    "            generated_text = response.generations[0].text\n",
    "            questions = generated_text.split('\\n')\n",
    "            cleaned_questions = set()\n",
    "            for question in questions:\n",
    "                if len(question) > 5:\n",
    "                    question = re.sub(r'\\d+\\.', '', question)\n",
    "                    question = question.replace('Q:', '')\n",
    "                    question = question.strip()\n",
    "                    if is_a_question(question) is True:\n",
    "                        cleaned_questions.add(question)\n",
    "            total_questions_generated += len(cleaned_questions)\n",
    "            questions_map[summary] = cleaned_questions\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "370ccdb9-4004-4865-b095-71840b7ce90a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total questions generated = 28\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Total questions generated = {total_questions_generated}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a726a133-93b9-4a77-a296-d77f3da4dea0",
   "metadata": {},
   "source": [
    "#### 4. Abstractive Question & Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "40e49f01-d549-4d1c-a527-56a1ced04b96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:36<00:00, 16.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.5 ms, sys: 10.1 ms, total: 88.7 ms\n",
      "Wall time: 1min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "qa_pairs = []\n",
    "\n",
    "for context, questions in tqdm(questions_map.items()):\n",
    "    for question in questions:\n",
    "        prompt = f\"\"\"Context = {context}\n",
    "        Question = {question}\n",
    "        Answer = \n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = client.generate(prompt=prompt, \n",
    "                               max_tokens=128, \n",
    "                               temperature=0, \n",
    "                               return_likelihoods='GENERATION')\n",
    "\n",
    "            generated_text = response.generations[0].text\n",
    "            answer = generated_text.strip()\n",
    "            qa_pairs.append((doc_name, context, question, answer))\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2ed3e-b255-4ff3-9141-bcae17413612",
   "metadata": {},
   "source": [
    "#### 5. Combine short summaries into a long form summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "951e0770-dcf6-445a-b1db-ccf6b3c16692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_form_summary = []\n",
    "for short_summary in cleaned_summaries:\n",
    "    short_summary = short_summary.replace('\\'', '')\n",
    "    long_form_summary.append(short_summary)\n",
    "long_form_summary = '\\n\\n'.join(long_form_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8681ce1-957b-4d06-a19e-f17655d689d5",
   "metadata": {},
   "source": [
    "#### 6. Write long form summary and QA pairs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3175b0f3-b6c3-43a6-b918-c53052eb452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./summaries/summary_5.txt', 'w') as out:\n",
    "    out.write(long_form_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f649fe-4eff-4fc9-af77-5a144b9d2fb6",
   "metadata": {},
   "source": [
    "#### 7. Write QA pairs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "60eb9d45-9649-4c91-896c-22c416a21615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_name</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>The context is a civil appeal filed by Bakshi ...</td>\n",
       "      <td>What is the position of the plaintiffs?</td>\n",
       "      <td>The plaintiffs are entitled to the reversion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>The context is a civil appeal filed by Bakshi ...</td>\n",
       "      <td>What is the effect of the first question?</td>\n",
       "      <td>The first question is about the nature of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>The context is a civil appeal filed by Bakshi ...</td>\n",
       "      <td>What is the effect of the award?</td>\n",
       "      <td>The effect of the award is that the plaintiffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>The context is a civil appeal filed by Bakshi ...</td>\n",
       "      <td>What is the nature of the award?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>The context is a civil appeal filed by Bakshi ...</td>\n",
       "      <td>What is the position of the defendants?</td>\n",
       "      <td>The defendants say that it gave Mst. Mohan Dei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_name                                      short_summary  \\\n",
       "0    5.txt  The context is a civil appeal filed by Bakshi ...   \n",
       "1    5.txt  The context is a civil appeal filed by Bakshi ...   \n",
       "2    5.txt  The context is a civil appeal filed by Bakshi ...   \n",
       "3    5.txt  The context is a civil appeal filed by Bakshi ...   \n",
       "4    5.txt  The context is a civil appeal filed by Bakshi ...   \n",
       "\n",
       "                                    question  \\\n",
       "0    What is the position of the plaintiffs?   \n",
       "1  What is the effect of the first question?   \n",
       "2           What is the effect of the award?   \n",
       "3           What is the nature of the award?   \n",
       "4    What is the position of the defendants?   \n",
       "\n",
       "                                              answer  \n",
       "0      The plaintiffs are entitled to the reversion.  \n",
       "1  The first question is about the nature of the ...  \n",
       "2  The effect of the award is that the plaintiffs...  \n",
       "3                                                     \n",
       "4  The defendants say that it gave Mst. Mohan Dei...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(qa_pairs, columns=['doc_name', 'short_summary', 'question', 'answer'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "085a52a8-ef54-43aa-af1b-f0a3385c8a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('./qa_pairs/qa_pairs_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f965d-7f58-45ed-80e7-cd93b82e9d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
